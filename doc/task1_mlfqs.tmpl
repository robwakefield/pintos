            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while preparing your 
>> submission, other than the Pintos documentation, course text, lecture notes 
>> and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (2 marks) 
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration.  
>> Identify the purpose of each in roughly 25 words.

>> A2: (4 marks) 
>> Draw a diagram that illustrates a nested donation in your structure and 
>> briefly explain how this works.

---- ALGORITHMS ----

>> A3: (3 marks) 
>> How do you ensure that the highest priority waiting thread wakes up first for
>> a (i) semaphore, (ii) lock, or (iii) condition variable?

>> A4: (3 marks)
>> Describe the sequence of events when a call to lock_acquire() causes a 
>> priority donation. 
>> How is nested donation handled?

>> A5: (3 marks)
>> Describe the sequence of events when lock_release() is called on a lock that 
>> a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> A6: (2 marks)
>> How do you avoid a race condition in thread_set_priority() when a thread 
>> needs to recompute its effective priority, but the donated priorities 
>> potentially change during the computation?
>> Can you use a lock to avoid the race?

---- RATIONALE ----

>> A7: (3 marks)
>> Why did you choose this design?  
>> In what ways is it superior to another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (2 marks)
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration. 
>> Identify the purpose of each in roughly 25 words.

Added to struct semaphore_elem:

  /* Used to order the list responsible for yielding to the correct thread after a semaphore is upped */
  int priority;   /* Priority of highest thread in semaphore waiter list */

Added to struct thread:

  /* Variables to hold computed values used in mlfqs */
  int nice;       /* Nice value for mlfqs */
  int recent_cpu; /* Recent CPU value for mlfqs */

---- ALGORITHMS ----

>> B2: (3 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2 and each has a 
>> recent_cpu value of 0. 
>> Fill in the table below showing the scheduling decision, the priority and the
>> recent_cpu values for each thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59     A
 4      4   0   0  62  61  59     A
 8      8   0   0  61  61  59     B
12      8   4   0  61  60  59     A
16     12   4   0  60  60  59     B
20     12   8   0  60  59  59     A
24     16   8   0  59  59  59     C
28     16   8   4  59  59  58     B
32     16  12   4  59  58  58     A
36     20  12   4  58  58  58     C

>> B3: (2 marks) 
>> Did any ambiguities in the scheduler specification make values in the table 
>> uncertain? 
>> If so, what rule did you use to resolve them?

When a running thread has its priority calculated and the result is equal to the priority of another ready thread, it is uncertain which of these threads should run next. The rule used to remove this ambiguity was to always add the running thread to the back of the queue with its new priority. This way if threads have the same priority they will follow a round robin schedule, but if the thread has the highest priority it will still remain the running thread.

---- RATIONALE ----

>> B4: (3 marks)
>> Briefly critique your design, pointing out advantages and disadvantages in 
>> your design choices.

Instead of implementing 64 separate ready queues, we used a single queue with threads ordered by their calculated priority. This allowed the implementation to work nicely with the priority scheduler and meant that the round robin requirement of equal priority threads would work with no extra code.

The recent_cpu, load_avg and priority calculations take place in thread_tick() and are run only when necessary in order to minimise the amount of processing time happening during the timer interrupt.

The fixed point functions are implemented as preprocesser macros in the file fixed-point.h. Macros were used instead of functions to keep the time cost of running these functions to a minimum and to make the code more readable. However this can make debugging more difficult as it can be hard to pinpoint where exactly the bug is.
